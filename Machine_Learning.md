# Machine Learning



## Supervised Learning

### Regression

Check an example in [notebook](notebooks/data-analysis/Boston_House_Price.ipynb)! 

* Linear Regression

The simplest LR is as below. It can be multi-dimentional depending on your input. It can also be Polynomial equation.

```
y=ax+b
```
   * Lasso Regression (L1)
   * Ridge Regression (L2)
   
It can easily see which component is more important, but hard to include interaction between features.
   
   
* Decision Tree


* Random Forest


* Bayesian

### Classification

Check an example in notebook!

* Logisitc Regression

* Naive Bayes

* Support Vector Machine (SVM)

* Decision Tree for Regression

* Random Forest

* Gradient Boosting

* KNN


### Enssemble/Stacking

Let's try out these algorithms on a Kaggle compettion

To increase the accuraccy there are many solutions

Let's visualizae the performance with manifold

We can also build an interactive streamlit app from our trained model.

## unsupervised Learning

* K-means

* PCA

## Deep Learning

Please check [here](Deep_Learning.md)


## More Resources

[https://jakevdp.github.io/PythonDataScienceHandbook/](https://jakevdp.github.io/PythonDataScienceHandbook/)







